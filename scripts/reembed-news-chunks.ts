/**
 * News Chunks ì¬ì„ë² ë”© ìŠ¤í¬ë¦½íŠ¸
 * 768 -> 1536 ì°¨ì› ë§ˆì´ê·¸ë ˆì´ì…˜ í›„ ì‹¤í–‰
 *
 * ì‹¤í–‰: npx ts-node scripts/reembed-news-chunks.ts
 * ë˜ëŠ”: npx tsx scripts/reembed-news-chunks.ts
 *
 * í™˜ê²½ë³€ìˆ˜ í•„ìš”:
 * - OPENAI_API_KEY
 * - NEXT_PUBLIC_SUPABASE_URL
 * - SUPABASE_SERVICE_KEY
 */

import OpenAI from 'openai'
import { createClient } from '@supabase/supabase-js'
import * as dotenv from 'dotenv'
import * as path from 'path'

// .env.local ë¡œë“œ
dotenv.config({ path: path.join(__dirname, '../.env.local') })

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
})

const supabase = createClient(
  (process.env.SUPABASE_URL || process.env.NEXT_PUBLIC_SUPABASE_URL)!,
  process.env.SUPABASE_SERVICE_KEY!
)

const BATCH_SIZE = 100  // DBì—ì„œ ê°€ì ¸ì˜¬ ì²­í¬ ìˆ˜
const EMBEDDING_BATCH_SIZE = 50  // OpenAI ë°°ì¹˜ í¬ê¸°

/**
 * ë°°ì¹˜ ì„ë² ë”© ìƒì„± (1536 ì°¨ì›)
 */
async function generateEmbeddingsBatch(texts: string[]): Promise<number[][]> {
  const response = await openai.embeddings.create({
    model: 'text-embedding-3-small',
    input: texts,
    dimensions: 1536
  })
  return response.data
    .sort((a, b) => a.index - b.index)
    .map(item => item.embedding)
}

/**
 * ëª¨ë“  ì²­í¬ ì¬ì„ë² ë”©
 */
async function reembedAllChunks() {
  console.log('ğŸ”„ News Chunks ì¬ì„ë² ë”© ì‹œì‘ (1536 ì°¨ì›)...\n')

  // ì„ë² ë”©ì´ í•„ìš”í•œ ì²­í¬ ìˆ˜ í™•ì¸
  const { count: totalCount, error: countError } = await supabase
    .from('news_chunks')
    .select('*', { count: 'exact', head: true })
    .is('embedding', null)

  if (countError) {
    console.error('âŒ ì²­í¬ ìˆ˜ ì¡°íšŒ ì‹¤íŒ¨:', countError.message)
    return
  }

  console.log(`ğŸ“Š ì¬ì„ë² ë”©ì´ í•„ìš”í•œ ì²­í¬ ìˆ˜: ${totalCount}`)

  if (totalCount === 0) {
    console.log('âœ… ëª¨ë“  ì²­í¬ê°€ ì´ë¯¸ ì„ë² ë”©ë˜ì–´ ìˆìŠµë‹ˆë‹¤!')
    return
  }

  let processed = 0
  let failed = 0
  let hasMore = true
  const startTime = Date.now()

  while (hasMore) {
    // ì„ë² ë”©ì´ ì—†ëŠ” ì²­í¬ ê°€ì ¸ì˜¤ê¸°
    const { data: chunks, error } = await supabase
      .from('news_chunks')
      .select('id, chunk_text')
      .is('embedding', null)
      .order('id', { ascending: true })
      .limit(BATCH_SIZE)

    if (error) {
      console.error('âŒ ì²­í¬ ì¡°íšŒ ì‹¤íŒ¨:', error.message)
      break
    }

    if (!chunks || chunks.length === 0) {
      hasMore = false
      break
    }

    // OpenAI ë°°ì¹˜ í¬ê¸°ë¡œ ë¶„í•  ì²˜ë¦¬
    for (let i = 0; i < chunks.length; i += EMBEDDING_BATCH_SIZE) {
      const batch = chunks.slice(i, i + EMBEDDING_BATCH_SIZE)
      const texts = batch.map(c => c.chunk_text)

      try {
        const embeddings = await generateEmbeddingsBatch(texts)

        // ê° ì²­í¬ ì—…ë°ì´íŠ¸
        for (let j = 0; j < batch.length; j++) {
          const { error: updateError } = await supabase
            .from('news_chunks')
            .update({ embedding: embeddings[j] })
            .eq('id', batch[j].id)

          if (updateError) {
            console.error(`âŒ ì²­í¬ ${batch[j].id} ì—…ë°ì´íŠ¸ ì‹¤íŒ¨:`, updateError.message)
            failed++
          } else {
            processed++
          }
        }

        // ì§„í–‰ë¥  í‘œì‹œ
        const progress = ((processed + failed) / totalCount! * 100).toFixed(1)
        const elapsed = ((Date.now() - startTime) / 1000).toFixed(0)
        process.stdout.write(`\râ³ ì§„í–‰: ${processed}/${totalCount} (${progress}%) - ê²½ê³¼: ${elapsed}s`)

        // Rate limiting (200ms ëŒ€ê¸°)
        await new Promise(resolve => setTimeout(resolve, 200))

      } catch (embeddingError: any) {
        console.error('\nâŒ ì„ë² ë”© ì˜¤ë¥˜:', embeddingError.message)

        // Rate limit ì˜¤ë¥˜ë©´ ë” ê¸´ ëŒ€ê¸°
        if (embeddingError.message?.includes('rate limit')) {
          console.log('â³ Rate limit - 10ì´ˆ ëŒ€ê¸°...')
          await new Promise(resolve => setTimeout(resolve, 10000))
        } else {
          // ë‹¤ë¥¸ ì˜¤ë¥˜ë©´ 5ì´ˆ ëŒ€ê¸° í›„ ê³„ì†
          await new Promise(resolve => setTimeout(resolve, 5000))
        }
        failed += batch.length
      }
    }
  }

  const totalTime = ((Date.now() - startTime) / 1000).toFixed(1)
  console.log('\n\nâœ… ì¬ì„ë² ë”© ì™„ë£Œ!')
  console.log(`   - ì„±ê³µ: ${processed}ê°œ`)
  console.log(`   - ì‹¤íŒ¨: ${failed}ê°œ`)
  console.log(`   - ì´ ì†Œìš”ì‹œê°„: ${totalTime}ì´ˆ`)

  // ìµœì¢… í™•ì¸
  const { count: remaining } = await supabase
    .from('news_chunks')
    .select('*', { count: 'exact', head: true })
    .is('embedding', null)

  if (remaining && remaining > 0) {
    console.log(`\nâš ï¸ ì•„ì§ ì„ë² ë”©ì´ í•„ìš”í•œ ì²­í¬: ${remaining}ê°œ`)
    console.log('   ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.')
  }
}

/**
 * ì„ë² ë”© ë¹„ìš© ì¶”ì •
 */
async function estimateCost() {
  const { count } = await supabase
    .from('news_chunks')
    .select('*', { count: 'exact', head: true })
    .is('embedding', null)

  if (!count) {
    console.log('ì„ë² ë”©ì´ í•„ìš”í•œ ì²­í¬ê°€ ì—†ìŠµë‹ˆë‹¤.')
    return
  }

  // í‰ê·  ì²­í¬ í¬ê¸°: ~500ì = ~125 í† í°
  const avgTokensPerChunk = 125
  const totalTokens = count * avgTokensPerChunk
  const costPer1MTokens = 0.02  // text-embedding-3-small ê°€ê²©
  const estimatedCost = (totalTokens / 1_000_000) * costPer1MTokens

  console.log('ğŸ’° ë¹„ìš© ì¶”ì •:')
  console.log(`   - ì²­í¬ ìˆ˜: ${count}ê°œ`)
  console.log(`   - ì˜ˆìƒ í† í°: ~${totalTokens.toLocaleString()}`)
  console.log(`   - ì˜ˆìƒ ë¹„ìš©: ~$${estimatedCost.toFixed(4)}`)
}

// CLI ì²˜ë¦¬
const command = process.argv[2] || 'run'

switch (command) {
  case 'run':
    reembedAllChunks().catch(console.error)
    break
  case 'estimate':
    estimateCost().catch(console.error)
    break
  default:
    console.log('ì‚¬ìš©ë²•:')
    console.log('  npx tsx scripts/reembed-news-chunks.ts run      - ì¬ì„ë² ë”© ì‹¤í–‰')
    console.log('  npx tsx scripts/reembed-news-chunks.ts estimate - ë¹„ìš© ì¶”ì •')
}
